{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "model_nlp-checkpoint.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LorgneSchilooch/Quiromanciers/blob/build%2Fmodel/notebook/.ipynb_checkpoints/model_nlp-checkpoint_with_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bynzt2Mn9fDG",
        "colab_type": "code",
        "outputId": "7176009e-372c-4a37-b3c1-10ca6496266e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import csv\n",
        "import os\n",
        "import spacy\n",
        "import numpy as np\n",
        "from tensorflow.python.keras import preprocessing\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import Sequential, callbacks, utils\n",
        "from tensorflow.python.keras.activations import linear, tanh\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras.losses import mse\n",
        "from tensorflow.python.keras.optimizers import SGD, Adam\n",
        "from tensorflow.python import keras\n",
        "# Pad your sequences so they are the same length\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ST4jxE69fDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = \"../data/biographie_df.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV7Uw_m19fDQ",
        "colab_type": "code",
        "outputId": "374b1ead-0b05-4405-eb03-a4d7f4edd993",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "df_biographie = pd.read_csv(filename, encoding=\"utf-8\", sep=\";\")\n",
        "print(df_biographie.head())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            name                                         biographie\n",
            "0         Eminem  Marshall Bruce Mathers III (born October 17, 1...\n",
            "1      Lady Gaga  Stefani Joanne Angelina Germanotta ( STEF-ən-e...\n",
            "2  Justin Bieber  Justin Drew Bieber (; born March 1, 1994) is a...\n",
            "3      Lil Wayne  Dwayne Michael Carter Jr. (born September 27, ...\n",
            "4    Miley Cyrus  Miley Ray Hemsworth (née Cyrus, born Destiny H...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2Fb7lrq9fDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!python -m spacy download en_core_web_sm\n",
        "#!python -m spacy download en_core_web_lg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3RcksL49fDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_data(x):\n",
        "  x = str(x)\n",
        "  return re.sub(r'\\(.*?\\)', '', x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILiZb7SYDW4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_biographie['biographie'] = df_biographie['biographie'].apply(lambda x: clean_data(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYxsK2rNDwYC",
        "colab_type": "code",
        "outputId": "6867c98d-6287-45bd-9201-891edf7a457a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "df_biographie"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>biographie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Eminem</td>\n",
              "      <td>Marshall Bruce Mathers III , known professiona...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lady Gaga</td>\n",
              "      <td>Stefani Joanne Angelina Germanotta  , known pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Justin Bieber</td>\n",
              "      <td>Justin Drew Bieber  is a Canadian singer-songw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Lil Wayne</td>\n",
              "      <td>Dwayne Michael Carter Jr. , known professional...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Miley Cyrus</td>\n",
              "      <td>Miley Ray Hemsworth  is an American singer, so...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>Jazz Jennings</td>\n",
              "      <td>Jazz Jennings  is an American YouTube personal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>Zaira Wasim</td>\n",
              "      <td>Zaira Wasim  is a former Indian actress who wo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>Noah Schnapp</td>\n",
              "      <td>Noah Schnapp  is an American actor. He is best...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>Madison De La Garza</td>\n",
              "      <td>Madison Lee De La Garza  is an American actres...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>Dafne Keen</td>\n",
              "      <td>Dafne Keen Fernández  is a British-Spanish act...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>144 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    name                                         biographie\n",
              "0                 Eminem  Marshall Bruce Mathers III , known professiona...\n",
              "1              Lady Gaga  Stefani Joanne Angelina Germanotta  , known pr...\n",
              "2          Justin Bieber  Justin Drew Bieber  is a Canadian singer-songw...\n",
              "3              Lil Wayne  Dwayne Michael Carter Jr. , known professional...\n",
              "4            Miley Cyrus  Miley Ray Hemsworth  is an American singer, so...\n",
              "..                   ...                                                ...\n",
              "139        Jazz Jennings  Jazz Jennings  is an American YouTube personal...\n",
              "140          Zaira Wasim  Zaira Wasim  is a former Indian actress who wo...\n",
              "141         Noah Schnapp  Noah Schnapp  is an American actor. He is best...\n",
              "142  Madison De La Garza  Madison Lee De La Garza  is an American actres...\n",
              "143           Dafne Keen  Dafne Keen Fernández  is a British-Spanish act...\n",
              "\n",
              "[144 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIrr0Pmk9fDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp_en = spacy.load('en_core_web_lg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxUZt5ni9fDh",
        "colab_type": "code",
        "outputId": "6489684a-c2f4-4251-ae17-9fa82fa19fad",
        "colab": {}
      },
      "source": [
        "nlp_en"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<spacy.lang.en.English at 0x13ec7ae10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eub0TksJ9fDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokens = []\n",
        "lemma = []\n",
        "pos = []\n",
        "\n",
        "for doc in nlp_en.pipe(df_biographie['biographie'].astype('unicode').values, batch_size=50,\n",
        "                        n_threads=3):\n",
        "    if doc.is_parsed:\n",
        "        tokens.append([n.text for n in doc])\n",
        "        lemma.append([n.lemma_ for n in doc])\n",
        "        pos.append([n.pos_ for n in doc])\n",
        "    else:\n",
        "        # We want to make sure that the lists of parsed results have the\n",
        "        # same number of entries of the original Dataframe, so add some blanks in case the parse fails\n",
        "        tokens.append(None)\n",
        "        lemma.append(None)\n",
        "        pos.append(None)\n",
        "\n",
        "df_biographie['species_tokens'] = tokens\n",
        "df_biographie['species_lemma'] = lemma\n",
        "df_biographie['species_pos'] = pos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ApqB7Ic9fDo",
        "colab_type": "code",
        "outputId": "ce633b0a-9686-4664-83dd-41e0b549130a",
        "colab": {}
      },
      "source": [
        "text = '\\n'.join([''.join(sentence) for sentence in df_biographie['species_tokens'][0]])\n",
        "print(type(text))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaySy4pT9fDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.python.keras import preprocessing\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras import Sequential, callbacks, utils\n",
        "from tensorflow.python.keras.activations import linear, tanh\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras.losses import mse\n",
        "from tensorflow.python.keras.optimizers import SGD, Adam\n",
        "from tensorflow.python import keras\n",
        "class charLSTMmodel():\n",
        "    \n",
        "    def fit(self,text,epochs=100):\n",
        "        self._load(text)\n",
        "        self._build()\n",
        "        self._train(epochs)\n",
        "        \n",
        "    def _load(self, text):\n",
        "        self.idx_token = dict(enumerate(set(self._tokenise(text)),start=2))\n",
        "        self.idx_token[0] = '<PAD>'\n",
        "        self.idx_token[1] = '<UNK>' \n",
        "        self.token_idx = {word:i for i,word in self.idx_token.items()}       \n",
        "        token_ids = [[self.token_idx[token] for token in self._tokenise(sentence)] for sentence in self._chunk(text)]\n",
        "        inouts = [tokens[:i+1] for tokens in token_ids for i in range(1,len(tokens))]\n",
        "        self.x_dim = max([len(x) for x in inouts]) - 1\n",
        "        self.y_dim = len(self.idx_token) \n",
        "        inouts = np.array(keras.preprocessing.sequence.pad_sequences(inouts,maxlen=self.x_dim + 1, padding='pre'))\n",
        "        self.X, self.Y = inouts[:,:-1], inouts[:,-1]\n",
        "        \n",
        "    def _tokenise(self,text):\n",
        "        return list(' '.join(text.split()).replace(\" \",\"_\"))\n",
        "\n",
        "    def generate(self,words,i=150):\n",
        "        for _ in range(i):\n",
        "            x = [self.token_idx[token] if token in self.token_idx else 1 for token in self._tokenise(words)] \n",
        "            x = keras.preprocessing.sequence.pad_sequences([x], maxlen=self.x_dim, padding = 'pre')\n",
        "            y_hat = self.model.predict_classes(x, verbose=0)[0] #maximise\n",
        "            words += self.idx_token[y_hat]\n",
        "            return words.replace(\"_\",\" \")\n",
        "    \n",
        "    def _chunk(self,text,chunk_size = 100):\n",
        "        return ''.join([c + '<S>' if not i % chunk_size else c for i,c in enumerate(text,start=1)]).split('<S>')\n",
        "\n",
        "    def _build(self):\n",
        "        self.model = keras.models.Sequential()\n",
        "        self.model.add(keras.layers.Embedding(self.y_dim, 10, input_length=self.x_dim))\n",
        "        self.model.add(keras.layers.LSTM(150, return_sequences = True))\n",
        "        self.model.add(keras.layers.LSTM(100))\n",
        "        self.model.add(keras.layers.Dense(self.y_dim, activation='softmax'))\n",
        "        self.model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    def _train(self,epochs):\n",
        "        earlystop =  keras.callbacks.EarlyStopping(monitor='loss', min_delta=0, patience=5, verbose=0, mode='auto')\n",
        "        onehot_y = keras.utils.to_categorical(self.Y, num_classes=self.y_dim)\n",
        "        self.model.fit(self.X, onehot_y, epochs=epochs, verbose=1, callbacks=[earlystop])  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDa6yzDY9fDv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vGByMdC9fDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CgDlKe-9fD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clstm = charLSTMmodel()\n",
        "clstm.fit(text, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvawZ7Yw9fD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clstm.generate(\"my name is Manitra\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq3hRsc19fD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}